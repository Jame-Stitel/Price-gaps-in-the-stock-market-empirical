{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN Classification With News\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting Started"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.repository import BarsRepo, DbLocation, DbSample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# image_dir = Path('../../data/charts/5min')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create File DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "N_AFTER_BARS = 5  # 5 / 0\n",
    "CHOSEN_N = 12  # from gap\n",
    "PRICE_DIFF_FROM = 0  # 5 / 0\n",
    "\n",
    "CHOSEN_N = CHOSEN_N - PRICE_DIFF_FROM  # FROM last bar in picture\n",
    "\n",
    "\n",
    "bars_repo = BarsRepo(DbLocation.LOCAL, DbSample.ALL)\n",
    "charts_df = bars_repo.get_charts_news_nth_price(n_after_bars=N_AFTER_BARS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "charts_df = charts_df.sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
    "# charts_df = charts_df[charts_df['news_count'] > 0]  # filter only gaps with news\n",
    "charts_df[f'n_{CHOSEN_N}'] = charts_df.apply(lambda row : str(int(json.loads(row[f'n_after_{PRICE_DIFF_FROM}'])[f'{CHOSEN_N}'] >= 0)), axis = 1)\n",
    "charts_df['filepath_jupyter'] = charts_df.apply(lambda row : f'../../{row[\"filepath\"]}', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(charts_df, train_size=0.7, shuffle=True, random_state=1)\n",
    "train_df, val_df = train_test_split(train_df, train_size=0.8, shuffle=True, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading Images and News Sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, x_col_img, x_col_attr, y_col, batch_size, target_size, shuffle=True):\n",
    "        self.df = df.copy()\n",
    "        self.x_col_img = x_col_img\n",
    "        self.x_col_attr = x_col_attr\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size\n",
    "\n",
    "    def __get_input_img(self, path, target_size):\n",
    "        image = tf.keras.preprocessing.image.load_img(path)\n",
    "        image_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        image_arr = tf.image.resize(image_arr,(target_size[0], target_size[1])).numpy()\n",
    "        return image_arr/255.\n",
    "\n",
    "    def __get_input_attr(self, value):\n",
    "        return value\n",
    "\n",
    "    def __get_output(self, label):\n",
    "        return int(label)\n",
    "\n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "        x_batch_img = np.asarray(\n",
    "            [self.__get_input_img(x, self.target_size) for x in batches[self.x_col_img]]\n",
    "        )\n",
    "        x_batch_attr = np.asarray(\n",
    "            [self.__get_input_attr(x) for x in batches[self.x_col_attr]]\n",
    "        )\n",
    "\n",
    "        y_batch = np.asarray(\n",
    "            [self.__get_output(y) for y in batches[self.y_col]]\n",
    "        )\n",
    "\n",
    "        return (x_batch_attr, x_batch_img), y_batch\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        x, y = self.__get_data(batches)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1.0, random_state=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "x_col_img = 'filepath_jupyter'\n",
    "x_col_attr = 'news_sentiment'\n",
    "y_col = f'n_{CHOSEN_N}'\n",
    "batch_size = 32\n",
    "target_size = (119, 86)  # (714, 516), (119, 86)\n",
    "\n",
    "train_generator = CustomDataGen(\n",
    "    train_df, x_col_img, x_col_attr, y_col=y_col, batch_size=batch_size, target_size=target_size\n",
    ")\n",
    "\n",
    "val_generator = CustomDataGen(\n",
    "    val_df, x_col_img, x_col_attr, y_col=y_col, batch_size=batch_size, target_size=target_size\n",
    ")\n",
    "\n",
    "test_generator = CustomDataGen(\n",
    "    test_df, x_col_img, x_col_attr, y_col=y_col, batch_size=batch_size, target_size=target_size, shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "inputs_attr = tf.keras.Input(shape=(1))\n",
    "x_attr = tf.keras.layers.Dense(32, activation='relu')(inputs_attr)\n",
    "model_attr = tf.keras.Model(inputs=inputs_attr, outputs=x_attr)\n",
    "\n",
    "\n",
    "inputs_img = tf.keras.Input(shape=(714, 516, 3))\n",
    "x_img = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')(inputs_img)\n",
    "x_img = tf.keras.layers.MaxPool2D(pool_size=2)(x_img)\n",
    "x_img = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu')(x_img)\n",
    "x_img = tf.keras.layers.MaxPool2D(pool_size=2)(x_img)\n",
    "x_img = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu')(x_img)\n",
    "x_img = tf.keras.layers.MaxPool2D(pool_size=2)(x_img)\n",
    "x_img = tf.keras.layers.Flatten()(x_img)\n",
    "x_img = tf.keras.layers.Dropout(0.5)(x_img)\n",
    "model_img = tf.keras.Model(inputs=inputs_img, outputs=x_img)\n",
    "\n",
    "combined_input = tf.keras.layers.concatenate([model_attr.output, model_img.output])\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(combined_input)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[model_attr.input, model_img.input], outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def get_f1(y_true, y_pred):\n",
    "    import tensorflow.keras.backend as K\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.000_1)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'AUC', get_f1]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f'training TIME: {end - start}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted = np.squeeze(model.predict(test_generator))\n",
    "actual = test_generator.df[test_generator.y_col]\n",
    "\n",
    "test_loss, test_acc, test_auc, test_f1 = model.evaluate(test_generator)\n",
    "print(f\"Test loss: {test_loss:.3f}\")\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")\n",
    "print(f\"Test AUC: {test_auc:.3f}\")\n",
    "print(f\"Test F1-score: {test_f1:.3f}\")\n",
    "\n",
    "r2 = r2_score(actual[:-9], predicted)\n",
    "print(\"Test R^2 Score: {:.5f}\".format(r2))\n",
    "\n",
    "print(f' - loss: **{test_loss:.3f}**; acc: **{test_acc:.3f}**; AUC: **{test_auc:.3f}**; F1: **{test_f1:.3f}**; R2: **{r2:.5f}**')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def m2tex(model, modelName):\n",
    "    stringlist = []\n",
    "    model.summary(line_length=70, print_fn=lambda x: stringlist.append(x))\n",
    "    del stringlist[1:-4:2]\n",
    "    del stringlist[-1]\n",
    "    for ix in range(1, len(stringlist) - 3):\n",
    "        tmp = stringlist[ix]\n",
    "        stringlist[ix] = tmp[0:31] + \"& \" + tmp[31:59] + \"& \" + tmp[59:] + \"\\\\\\\\ \\hline\"\n",
    "    stringlist[0] = \"Model: {} \\\\\\\\ \\hline\".format(modelName)\n",
    "    stringlist[1] = stringlist[1] + \" \\hline\"\n",
    "    stringlist[-4] += \" \\hline\"\n",
    "    stringlist[-3] += \" \\\\\\\\\"\n",
    "    stringlist[-2] += \" \\\\\\\\\"\n",
    "    stringlist[-1] += \" \\\\\\\\ \\hline\"\n",
    "    prefix = [\"\\\\begin{table}[]\", \"\\\\begin{tabular}{lll}\"]\n",
    "    suffix = [\"\\end{tabular}\", \"\\caption{{Model summary for {}.}}\".format(modelName), \"\\label{tab:model-summary}\",\n",
    "              \"\\end{table}\"]\n",
    "    stringlist = prefix + stringlist + suffix\n",
    "    out_str = \" \\n\".join(stringlist)\n",
    "    out_str = out_str.replace(\"_\", \"\\_\")\n",
    "    out_str = out_str.replace(\"#\", \"\\#\")\n",
    "    print(out_str)\n",
    "\n",
    "\n",
    "m2tex(model, 'OLA')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}